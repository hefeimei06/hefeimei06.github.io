<!DOCTYPE HTML>
<html lang="en"><head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-211172484-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-211172484-2');
</script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Hefei Mei</title>
  
  <meta name="author" content="Hefei">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hefei Mei </name>
              </p>


	      <p> Hi, I am Hefei Mei (Ê¢ÖÈπ§È£û), a second year CS PhD Student studying at the <a href="https://www.cityu.edu.hk/" target="_blank">City University of Hong Kong</a>, supervised by Prof. <a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>. 
		      Before that, I received B.S and M.S in Information and Communication Engineering at <a href="https://www.uestc.edu.cn/" target="_blank">University of Electronic Science and Technology of China</a>, supervised by Prof. <a href="https://www.sice.uestc.edu.cn/info/1450/11693.htm">Hongliang Li</a>. 
              </p>
              <p>
                My research interest lies in Computer Vision, Trustworthy AI, etc. Currently, I am exploring adversarial robustness of Large Vision Language Models.
              </p>
              <p> 
                Please feel free to drop me an Email for any form of communication or collaboration!
              </p>
              <p style="text-align:center">
		<a href="mailto:hefeimei2-c@my.cityu.edu.hk">Email</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=H04y9fEAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/hefeimei06">Github</a> &nbsp/&nbsp
                <a href="images/wechat.jpg">WeChat</a> &nbsp/&nbsp
		<a href="https://www.xiaohongshu.com/user/profile/5ec5430b000000000101cbb1">Red Notes (Â∞èÁ∫¢‰π¶Ôºâ</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:90%;max-width:100%" alt="profile photo" src="images/hefei.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        
        
        
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
        <tr>
          <td>
            <heading>üî•What's New</heading>
            <div style="height: 120px; overflow: auto;">
              <ul> 
		<li> 2025/04/11 One paper got accepted by AAAI 2025! Link here: <a href="https://arxiv.org/pdf/2408.08502" target="_blank"> IDC </a></li>
		<li> 2024/09/01 I will start my Ph.D degree at City University of Hong Kong. See you in Hong Kong!
              </ul>
            </div>
          </td>
        </tr>
      </tbody></table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Publications <font size=4>[<a href="https://scholar.google.com/citations?user=H04y9fEAAAAJ&hl=zh-CN"><font size=4><i>Google Scholar</i></font></a>]</font></heading>
              

            </td>
          </tr>
        </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr style="vertical-align:left;">
            <td style="padding:20px;width:35%;vertical-align:center">
              <img src="images/veattack.png" alt="3DSP" width="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:center">
              <a href="https://arxiv.org/pdf/2505.17440" id="3DSP">
                <papertitle>VEAttack: Downstream-agnostic Vision Encoder Attack against Large Vision Language Models
                </papertitle>
              </a>
              <br>
              <strong>Hefei Mei</strong>, Zirui Wang, Shen You, <a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>, <a href="http://www.changxu.xyz/">Chang Xu</a>
              <br>
              <font color="#38b000"><em><strong>Preprint </strong></em></font>
              <br>
              <p>
                 While existing effective attacks always focus on task-specific white-box settings, these approaches are limited in the context of LVLMs, which are designed for diverse downstream tasks and require expensive full-model gradient computations. Motivated by the pivotal role and wide adoption of the vision encoder in LVLMs, we propose a simple yet effective Vision Encoder Attack (VEAttack), which targets the vision encoder of LVLMs only. </p>
            </td>
          </tr>
  
    <tr style="vertical-align:left;">
            <td style="padding:20px;width:35%;vertical-align:center">
              <img src="images/idc.png" alt="3DSP" width="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:center">
              <a href="https://arxiv.org/pdf/2408.08502" id="3DSP">
                <papertitle>Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness
                </papertitle>
              </a>
              <br>
              <strong>Hefei Mei</strong>, <a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>, <a href="http://www.changxu.xyz/">Chang Xu</a>
              <br>
              <font color="#38b000"><em><strong>AAAI Conference on Artificial Intelligence (AAAI-25) </strong></em></font>
              <br>
              <p>
                We introduce an efficient Image-to-Image diffusion classifier with a pruned U-Net structure and reduced diffusion timesteps. Besides the framework, we redesign the optimization objective of diffusion models to fit the target of image classification, where a new classification loss is incorporated in the DM-based image translation framework to distinguish the generated label from those of other classes. We conduct sufficient evaluations of the proposed classifier under various attacks on popular benchmarks. </p>
            </td>
          </tr>
  
  
  <tr style="vertical-align:left;">
            <td style="padding:20px;width:35%;vertical-align:center">
              <img src="images/grsdet.png" alt="3DSP" width="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:center">
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231225015759" id="3DSP">
                <papertitle>GRSDet: Learning to Generate Local Reverse Samples for Few-shot Object Detection
                </papertitle>
              </a>
              <br>
              <strong>Hefei Mei</strong>, Taijin Zhao, Shiyuan Tang, <a href="https://qiuheqian.github.io/">Heqian Qiu</a>, <a href="https://wanglanxiao.github.io/">Lanxiao Wang</a>, Minjian Zhang, <a href="https://www.sice.uestc.edu.cn/info/1450/11678.htm">Fanman Meng</a>, <a href="https://www.sice.uestc.edu.cn/info/1450/11693.htm">Hongliang Li</a>
              <br>
              <font color="#38b000"><em><strong>Neurocomputing </strong></em></font>
              <br>
              <p>
                We consider the conversion relationship between non-similar samples of the same category (Local Reverse Samples, LRSamples) in the base class can be learned and also transferred to the novel class. So we propose the selection rule and intra-class feature converter (IFC) of LRSamples in our Center Calibration Variance Augmentation (CCVA) module to adaptively adjust the center position of the novel class distribution for FSOD. Moreover, we propose a Feature Density Boundary Optimization (FDBO) module to adaptively adjust the importance of samples depending on their distance from the decision boundary. </p>
            </td>
          </tr>

  
  <tr style="vertical-align:left;">
            <td style="padding:20px;width:35%;vertical-align:center">
              <img src="images/decrossdet.png" alt="3DSP" width="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:center">
              <a href="https://ieeexplore.ieee.org/document/10008820" id="3DSP">
                <papertitle>DE-CrossDet: Divisible and Extensible Crossline Representation for Object Detection
                </papertitle>
              </a>
              <br>
              <strong>Hefei Mei</strong>, <a href="https://www.sice.uestc.edu.cn/info/1450/11693.htm">Hongliang Li</a>, <a href="https://qiuheqian.github.io/">Heqian Qiu</a>, Jianhua Cui, <a href="https://longrongyang.github.io/yanglongrong.github.io/">Longrong Yang</a>
              <br>
              <font color="#38b000"><em><strong>IEEE International Conference on Visual Communications and Image Processing (VCIP-22) </strong></em></font>
              <br>
              <p>
                We present a new feature extraction method, DE-Crossline, which can enhance the original crossline representation to capture more accurate object information. Specifically, we divide the crossline into several segments, each of which extracts the maximum activation key point respectively to reduce the impact of noise mentioned above. Furthermore, considering various shapes and sizes of objects, we design a Deformable Width Extension Module to learn a suitable width of each crossline, so as to capture richer object information. </p>
            </td>
          </tr>
	

  </tbody></table>  



    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="90%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cityu.png" width="70%" ></td>
            <td width="70%" valign="center">
              <b>City University of Hong Kong</b>
	      <br> Hong Kong
              <br> 2024.09 - present<br>
              <br> <b>Ph.D. in Computer Science</b>
	      <br> GPA: 4.15 / 4.30
              <br> Supervisor: Prof. <a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/uestc2.png" width="70%" ></td>
            <td width="70%" valign="center">
              <b>University of Electronic Science and Technology of China </b>
	      <br> Chengdu, China
              <br> 2021.09 - 2024.06<br>
              <br> <b>M.S. in Information and Communication Engineering</b>
              <br> GPA: 3.88 / 4.00
              <br> Supervisor: Prof. <a href="https://www.sice.uestc.edu.cn/info/1450/11693.htm">Hongliang Li</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/uestc2.png" width="70%" ></td>
            <td width="70%" valign="center">
              <b>University of Electronic Science and Technology of China </b>
	      <br> Chengdu, China
              <br> 2017.09 - 2021.06<br>
              <br> <b>B.S. in Electronic and Information Engineering</b>
              <br> GPA: 3.92 / 4.00
            </td>
          </tr>

          </tbody>
        </table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Service</heading>
                <ul>
                  <li><b>Journal Reviewer</b>: IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Transactions on Multimedia </li>
                  <li><b>Conference Reviewer</b>: NeurIPS (2024-), ICML (2025), ICLR (2025), CVPR (2025), AAAI (2026), AISTATS (2025-) </li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>

      
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Teaching</heading>
                <ul>
                  <li>2025, Lab Tutor, CS1302: Introduction to Computer Programming, Cityu University of Hong Kong </li>
                  <li>2024, Teaching Assistant, CS1302: Introduction to Computer Programming, Cityu University of Hong Kong </li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>

      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Awards</heading>
                <ul>
                  <li>National Scholarship in 2019, 2020, 2022 </li>
                  <li>First Prize in 2023 Chinese Graduate Electronic Design Competition </li>
                  <li>Second Prize in 2021 Chinese Graduate Mathematical Modeling Competition </li>
                  <li>Meritorious Winner in 2019 U.S. Mathematical Contest in Modeling </li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Miscellaneous</heading>
              <ul>
		<li> Though excellence is a tough pursuit, I've come a long way to get to you. I try to stay positive and resilient in the face of challenges. If you're having a tough time and would like someone to talk to, feel free to reach out!
                </li>
                <li>I like hiking, astronomy and making new friends.</li>
                <li>I like all cute animals like Samoyed, Border Collie, Ragdoll.</li> 
                <li>I like music, especially piano.</li> 

              </ul>
            </td>
          </tr>
        </tbody></table>


  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=350&t=tt&d=K63nzDEs8onGda3y8A6lWzEK7JEN_VET83AkgeOhXx4'></script>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template courtesy: <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        </table>
      </td>
    </tr>
  </table>
</body>




</html>

